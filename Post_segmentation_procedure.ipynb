{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "716f490b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import skimage.io as skio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import porespy as ps\n",
    "import os\n",
    "import skimage\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d713e3",
   "metadata": {},
   "source": [
    "# Step 1\n",
    "### This code is the first step after manual segmentation in Avizo. We need to rescale our images before giving them to the StyleGAN2ADA because it was designed to work with 0-255 range. This way, for each segmentatied phase, we give a corresponding value in 0-255 range. Note that as input, we take .tif files, and as output, we provide .png files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6891e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image processing completed.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def process_images(input_folder, output_folder):\n",
    "    # Create the output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Get the list of files in the input folder\n",
    "    file_list = os.listdir(input_folder)\n",
    "\n",
    "    for filename in file_list:\n",
    "        if filename.endswith('.tif'):\n",
    "            # Open the image\n",
    "            image_path = os.path.join(input_folder, filename)\n",
    "            image = Image.open(image_path)\n",
    "\n",
    "            # Create a new image with modified pixel values\n",
    "            modified_image = Image.new('L', image.size)  # 'L' mode for grayscale images\n",
    "\n",
    "            # Iterate over each pixel and modify its value\n",
    "            width, height = image.size\n",
    "            for x in range(width):\n",
    "                for y in range(height):\n",
    "                    pixel_value = image.getpixel((x, y))\n",
    "\n",
    "                    if pixel_value == 1:\n",
    "                        modified_image.putpixel((x, y), 0)\n",
    "                    elif pixel_value == 2:\n",
    "                        modified_image.putpixel((x, y), 85)\n",
    "                    elif pixel_value == 3:\n",
    "                        modified_image.putpixel((x, y), 170)\n",
    "                    elif pixel_value == 4:\n",
    "                        modified_image.putpixel((x, y), 255)\n",
    "\n",
    "            # Save the modified image in the output folder\n",
    "            output_filename = os.path.splitext(filename)[0] + '.png'\n",
    "            output_path = os.path.join(output_folder, output_filename)\n",
    "            modified_image.save(output_path)\n",
    "\n",
    "            # Close the images\n",
    "            image.close()\n",
    "            modified_image.close()\n",
    "\n",
    "    print(\"Image processing completed.\")\n",
    "\n",
    "# Specify the input and output folders\n",
    "input_folder = r'C:\\Users\\UGOLKOEA\\Desktop\\PhD_Thesis\\Images\\Good\\20\\Segmented'\n",
    "output_folder = r'C:\\Users\\UGOLKOEA\\Desktop\\PhD_Thesis\\Images\\Good\\20\\Segm_scale'\n",
    "\n",
    "# Process the images\n",
    "process_images(input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d272fd88",
   "metadata": {},
   "source": [
    "# Step 2\n",
    "## In this step 2, we expand the training dataset. The file below can take .png files in the folder, extract subimages with pre-set overlap, and save them in the separate folder. Here the images with size 1024x1024 are generated. We use the images from the Step 1. After step 2, the images are ready for the StyleGAN2ADA. Archive them in .zip and don't forget the json configuration file. Give the correct name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "90efde69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub-images extracted from 1.png and saved in C:\\Users\\UGOLKOEA\\Desktop\\PhD_Thesis\\Images\\Good\\20\\Simple_1024.\n",
      "Sub-images extracted from 10.png and saved in C:\\Users\\UGOLKOEA\\Desktop\\PhD_Thesis\\Images\\Good\\20\\Simple_1024.\n",
      "Sub-images extracted from 11.png and saved in C:\\Users\\UGOLKOEA\\Desktop\\PhD_Thesis\\Images\\Good\\20\\Simple_1024.\n",
      "Sub-images extracted from 12.png and saved in C:\\Users\\UGOLKOEA\\Desktop\\PhD_Thesis\\Images\\Good\\20\\Simple_1024.\n",
      "Sub-images extracted from 13.png and saved in C:\\Users\\UGOLKOEA\\Desktop\\PhD_Thesis\\Images\\Good\\20\\Simple_1024.\n",
      "Sub-images extracted from 14.png and saved in C:\\Users\\UGOLKOEA\\Desktop\\PhD_Thesis\\Images\\Good\\20\\Simple_1024.\n",
      "Sub-images extracted from 2.png and saved in C:\\Users\\UGOLKOEA\\Desktop\\PhD_Thesis\\Images\\Good\\20\\Simple_1024.\n",
      "Sub-images extracted from 3.png and saved in C:\\Users\\UGOLKOEA\\Desktop\\PhD_Thesis\\Images\\Good\\20\\Simple_1024.\n",
      "Sub-images extracted from 4.png and saved in C:\\Users\\UGOLKOEA\\Desktop\\PhD_Thesis\\Images\\Good\\20\\Simple_1024.\n",
      "Sub-images extracted from 5.png and saved in C:\\Users\\UGOLKOEA\\Desktop\\PhD_Thesis\\Images\\Good\\20\\Simple_1024.\n",
      "Sub-images extracted from 6.png and saved in C:\\Users\\UGOLKOEA\\Desktop\\PhD_Thesis\\Images\\Good\\20\\Simple_1024.\n",
      "Sub-images extracted from 7.png and saved in C:\\Users\\UGOLKOEA\\Desktop\\PhD_Thesis\\Images\\Good\\20\\Simple_1024.\n",
      "Sub-images extracted from 8.png and saved in C:\\Users\\UGOLKOEA\\Desktop\\PhD_Thesis\\Images\\Good\\20\\Simple_1024.\n",
      "Sub-images extracted from 9.png and saved in C:\\Users\\UGOLKOEA\\Desktop\\PhD_Thesis\\Images\\Good\\20\\Simple_1024.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def extract_sub_images(input_folder, output_folder, overlap_percentage):\n",
    "    # Create the output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Get a list of all .png files in the input folder\n",
    "    png_files = [file for file in os.listdir(input_folder) if file.endswith('.png')]\n",
    "\n",
    "    c = 0\n",
    "    for png_file in png_files:\n",
    "        # Load the .png image\n",
    "        png_path = os.path.join(input_folder, png_file)\n",
    "        image = Image.open(png_path)\n",
    "\n",
    "        # Calculate the overlap amount based on the overlap percentage\n",
    "        overlap_amount = int((1024 * overlap_percentage) / 100)\n",
    "\n",
    "        # Calculate the number of sub-images in each dimension with the overlap\n",
    "        num_sub_images_x = (image.width - overlap_amount) // (1024 - overlap_amount)\n",
    "        num_sub_images_y = (image.height - overlap_amount) // (1024 - overlap_amount)\n",
    "\n",
    "        for i in range(num_sub_images_x):\n",
    "            for j in range(num_sub_images_y):\n",
    "                # Calculate the starting coordinates of the sub-image\n",
    "                x_start = i * (1024 - overlap_amount)\n",
    "                y_start = j * (1024 - overlap_amount)\n",
    "\n",
    "                # Extract the sub-image\n",
    "                sub_image = image.crop((x_start, y_start, x_start + 1024, y_start + 1024))\n",
    "\n",
    "                # Save the sub-image as a .png file with a six-digit name\n",
    "                sub_image_name = f\"img_{c}.png\"\n",
    "                output_path = os.path.join(output_folder, sub_image_name)\n",
    "                sub_image.save(output_path)\n",
    "                c += 1\n",
    "\n",
    "        print(f\"Sub-images extracted from {png_file} and saved in {output_folder}.\")\n",
    "\n",
    "# Example usage\n",
    "input_folder = r\"C:\\Users\\UGOLKOEA\\Desktop\\PhD_Thesis\\Images\\Good\\20\\Segm_scale\"\n",
    "output_folder = r\"C:\\Users\\UGOLKOEA\\Desktop\\PhD_Thesis\\Images\\Good\\20\\00000\"\n",
    "overlap_percentage = 80  # Set the desired overlap percentage\n",
    "extract_sub_images(input_folder, output_folder, overlap_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f67dcc",
   "metadata": {},
   "source": [
    "# Step 3\n",
    "## After the StyleGAN2ADA is trained and working well, it generates images with values in some range. This piece of code takes these artificially generated images and put them back into a single-value values for each pixel. For the Super-Resolution code, we should choose 0, 1, 2, 3, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6121aaf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image processing completed.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def process_images(input_folder, output_folder):\n",
    "    # Create the output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Get the list of files in the input folder\n",
    "    file_list = os.listdir(input_folder)\n",
    "\n",
    "    for filename in file_list:\n",
    "        if filename.endswith('.png'):\n",
    "            # Open the image\n",
    "            image_path = os.path.join(input_folder, filename)\n",
    "            image = Image.open(image_path)\n",
    "\n",
    "            # Create a new image with modified pixel values\n",
    "            modified_image = Image.new('L', image.size)  # 'L' mode for grayscale images\n",
    "\n",
    "            # Iterate over each pixel and modify its value\n",
    "            width, height = image.size\n",
    "            for x in range(width):\n",
    "                for y in range(height):\n",
    "                    pixel_value = image.getpixel((x, y))\n",
    "\n",
    "                    if pixel_value > -30 and pixel_value < 45:\n",
    "                        modified_image.putpixel((x, y), 0)\n",
    "                    elif pixel_value > 45 and pixel_value < 130:\n",
    "                        modified_image.putpixel((x, y), 85)\n",
    "                    elif pixel_value > 130 and pixel_value < 210:\n",
    "                        modified_image.putpixel((x, y), 170)\n",
    "                    elif pixel_value > 210 and pixel_value < 275:\n",
    "                        modified_image.putpixel((x, y), 255)\n",
    "\n",
    "            # Save the modified image in the output folder\n",
    "            output_filename = os.path.splitext(filename)[0] + '.png'\n",
    "            output_path = os.path.join(output_folder, output_filename)\n",
    "            modified_image.save(output_path)\n",
    "\n",
    "            # Close the images\n",
    "            image.close()\n",
    "            modified_image.close()\n",
    "\n",
    "    print(\"Image processing completed.\")\n",
    "\n",
    "# Specify the input and output folders\n",
    "input_folder = r'C:\\Users\\UGOLKOEA\\Desktop\\test\\try_here'\n",
    "output_folder = r'C:\\Users\\UGOLKOEA\\Desktop\\PhD_Thesis\\Images\\Good\\20\\Art_generated'\n",
    "\n",
    "# Process the images\n",
    "process_images(input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff71b364-c5a2-4f14-be80-e0c397f19320",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3b54da2",
   "metadata": {},
   "source": [
    "## This piece of code was generated for the purpose of Avizo DL segmentation. To run their code, we need to stack our 2D images in the first stack, and to stack our segmented labels into the second stack. This code goes into the folder with our 2D images and stack them into the single 3D. Then, we can give this stack into the Avizo ML segmentation algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7658dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tifffile as tiff\n",
    "\n",
    "# Path to the folder containing the PNG images\n",
    "folder_path = r\"C:\\Users\\UGOLKOEA\\Desktop\\PhD_Thesis\\Images\\Good\\20\\Art_generated\"\n",
    "\n",
    "# Get a list of all PNG files in the folder\n",
    "png_files = [f for f in os.listdir(folder_path) if f.endswith(\".png\")]\n",
    "\n",
    "# Sort the files alphabetically\n",
    "png_files.sort()\n",
    "\n",
    "# Load the first image to get the dimensions\n",
    "first_image_path = os.path.join(folder_path, png_files[0])\n",
    "first_image = Image.open(first_image_path)\n",
    "width, height = first_image.size\n",
    "\n",
    "# Create an empty 3D volume\n",
    "volume = np.zeros((len(png_files), height, width), dtype=np.uint8)\n",
    "\n",
    "# Iterate over the PNG files and stack them in the volume\n",
    "for i, png_file in enumerate(png_files):\n",
    "    image_path = os.path.join(folder_path, png_file)\n",
    "    image = Image.open(image_path)\n",
    "    volume[i, :, :] = np.array(image)\n",
    "\n",
    "# Save the volume as a TIFF file\n",
    "output_directory = r\"C:\\Users\\UGOLKOEA\\Desktop\\PhD_Thesis\\Images\\Good\\20\"\n",
    "output_path = os.path.join(output_directory, \"output.tiff\")\n",
    "tiff.imsave(output_path, volume)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
